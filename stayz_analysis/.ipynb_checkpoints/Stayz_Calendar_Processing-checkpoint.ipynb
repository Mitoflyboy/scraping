{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import datetime\n",
    "import re\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from calendar import monthrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multiple files found in ZIP file. Only one file per ZIP: ['stayz_calendar_2018-02-23.json', '__MACOSX/', '__MACOSX/._stayz_calendar_2018-02-23.json']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e370db9158b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m js = pd.read_json('/Users/taj/GitHub/scraping/chrome_stayz_calendar/WebData/stayz_calendar_' + date_str + '.json.zip'\n\u001b[0;32m----> 5\u001b[0;31m                  ,compression='zip')\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_unit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     )\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunksize can only be passed if lines=True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    443\u001b[0m             data, _ = _get_handle(filepath_or_buffer, 'r',\n\u001b[1;32m    444\u001b[0m                                   \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                                   compression=self.compression)\n\u001b[0m\u001b[1;32m    446\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 raise ValueError('Multiple files found in ZIP file.'\n\u001b[1;32m    369\u001b[0m                                  \u001b[0;34m' Only one file per ZIP: {}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                                  .format(zip_names))\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;31m# XZ Compression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Multiple files found in ZIP file. Only one file per ZIP: ['stayz_calendar_2018-02-23.json', '__MACOSX/', '__MACOSX/._stayz_calendar_2018-02-23.json']"
     ]
    }
   ],
   "source": [
    "#date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "date_str = '2018-02-23'\n",
    "\n",
    "js = pd.read_json('/Users/taj/GitHub/scraping/chrome_stayz_calendar/WebData/stayz_calendar_' + date_str + '.json')\n",
    "#                 ,compression='zip')\n",
    "\n",
    "js.reset_index(drop=True)\n",
    "js.set_index('property_id')\n",
    "\n",
    "# Change values of -1.0 into NaN for stats analysis\n",
    "#js.loc[js['review_count'] == -1.0, 'review_count'] = np.nan\n",
    "#js.loc[js['review_value'] == -1.0, 'review_value'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(js.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datetime.date.today()\n",
    "mr = monthrange(d.year, d.month )\n",
    "\n",
    "cur_month = d.month\n",
    "cur_year = d.year\n",
    "\n",
    "\n",
    "first_page = True\n",
    "\n",
    "\n",
    "\n",
    "fp = open('/Users/taj/GitHub/scraping/chrome_stayz_calendar/WebData/stayz_processed_calendar_' + date_str + '.json', 'w')\n",
    "\n",
    "\n",
    "for index, row in js.iterrows():   \n",
    "    \n",
    "    all_months = {}\n",
    "    \n",
    "    cur_month = d.month\n",
    "\n",
    "    raw_cal = \"<html><body><table>\" + row['calendar'] + \"</table></body></html>\"\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(raw_cal,'lxml') # Parse the HTML as a string\n",
    "    soup_tables = soup.findAll('tbody')# Grab the first table\n",
    "    \n",
    "    \n",
    "    month_tb_count = 1\n",
    "\n",
    "    for month_tb in soup_tables:\n",
    " \n",
    "        cells = month_tb.findAll(\"td\")\n",
    "        \n",
    "        for td in cells:\n",
    "            try:\n",
    "                day_val = int(td.text)\n",
    "\n",
    "                date_full = datetime.date(cur_year,cur_month,day_val)\n",
    "\n",
    "                m1 = None\n",
    "                m2 = None\n",
    "                m3 = None\n",
    "                m4 = None\n",
    "\n",
    "                #----------------------------------------------------------\n",
    "                # Check if DEP and ARR can both be on the same day\n",
    "                # for consecutive bookings?\n",
    "\n",
    "                # If its an unavailable date then mark: \n",
    "                m1 = re.search('c-calendar--unavailable', str(td))\n",
    "\n",
    "                if m1 is not None:\n",
    "                    all_months[str(date_full)] = 'UVL' # Unavailable day\n",
    "\n",
    "                # If its an unavailable date then mark: \n",
    "                m2 = re.search('c-calendar--arrival-day', str(td))\n",
    "\n",
    "                if m2 is not None:\n",
    "                    all_months[str(date_full)] = 'ARR' # Arrival day\n",
    "\n",
    "                # If its an unavailable date then mark: \n",
    "                m3 = re.search('c-calendar--departure-day', str(td))\n",
    "\n",
    "                if m3 is not None:\n",
    "                    all_months[str(date_full)] = 'DEP' # Departure day\n",
    "\n",
    "                m4 = re.search('c-calendar--available', str(td))\n",
    "                if m4 is not None:\n",
    "                    all_months[str(date_full)] = 'AVL' # Available day\n",
    "\n",
    "\n",
    "            except ValueError:\n",
    "                day_val = None\n",
    "\n",
    "        # Move to the next month\n",
    "        cur_month += 1\n",
    "        month_tb_count += 1\n",
    "\n",
    "    \n",
    "    cal_details = {}\n",
    "    cal_details['property_id'] = row['property_id']\n",
    "    cal_details['calendar'] = all_months\n",
    "    \n",
    "    if first_page is True:\n",
    "        fp.write('[\\n')\n",
    "        first_page = False\n",
    "    else:\n",
    "        fp.write('\\n,')\n",
    "        \n",
    "    # Write the data to JSON\n",
    "    json.dump(cal_details, fp)\n",
    "\n",
    "\n",
    "    \n",
    "# Close out the JSON format\n",
    "fp.write('\\n]')    \n",
    "\n",
    "# Tidy up\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Processed Calendar file\n",
    "p = pd.read_json('/Users/taj/GitHub/scraping/chrome_stayz_calendar/WebData/stayz_processed_calendar_' + date_str + '.json')\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file for writing out the bookings details:\n",
    "fp = open('/Users/taj/GitHub/scraping/chrome_stayz_calendar/WebData/stayz_bookings_' + date_str + '.json', 'w')\n",
    "\n",
    "first_page = True\n",
    "\n",
    "# Iterate over each entry in the Processed Calendar file:\n",
    "for index, row in p.iterrows():  \n",
    "    \n",
    "    c = row['calendar']\n",
    "    #print(c)\n",
    "    \n",
    "    pid = row['property_id']\n",
    "    \n",
    "    \n",
    "    #c2 = c.to_dict()[0]\n",
    "    #type(c2)\n",
    "\n",
    "\n",
    "    days_count = 0\n",
    "    avl_count = 0\n",
    "    dep_count = 0\n",
    "    arr_count = 0\n",
    "    uvl_count = 0\n",
    "\n",
    "    booking_count = 0\n",
    "\n",
    "\n",
    "    dates = list(c.keys())\n",
    "\n",
    "    min_dateIndex = 0\n",
    "    max_dateIndex = len(dates)\n",
    "\n",
    "    #print(\"Number of days: \" + str(max_dateIndex))\n",
    "    \n",
    "    while (min_dateIndex < max_dateIndex):\n",
    "\n",
    "\n",
    "        date = dates[min_dateIndex]\n",
    "        status = c[date]\n",
    "\n",
    "\n",
    "        # Count the total number of days\n",
    "        days_count += 1\n",
    "\n",
    "        if( status == 'AVL'):\n",
    "            avl_count += 1\n",
    "\n",
    "        if( status == 'ARR'):\n",
    "            arr_count += 1\n",
    "            # Iterate while the days are Unavailble until we find a Departure\n",
    "\n",
    "            # Keep the arrival date:\n",
    "            date_arr = date\n",
    "\n",
    "            # Reset the count for this booking\n",
    "            booking_days = 0\n",
    "\n",
    "            # Move to the next day.\n",
    "            # Breaks if they arrive on the last day of the 6th month!!!\n",
    "            min_dateIndex += 1\n",
    "            \n",
    "            if(min_dateIndex < max_dateIndex): \n",
    "                date = dates[min_dateIndex]\n",
    "                status = c[date]\n",
    "            else:\n",
    "                date = None\n",
    "                status = None\n",
    "            \n",
    "\n",
    "            while(( status != 'DEP') & (min_dateIndex < max_dateIndex)):\n",
    "                date = dates[min_dateIndex]\n",
    "                status = c[date]\n",
    "\n",
    "                # Departure date doesnt count as a booked date, but as an available date\n",
    "                booking_days += 1\n",
    "\n",
    "                days_count += 1\n",
    "\n",
    "                min_dateIndex += 1\n",
    "                \n",
    "                # on the last day of the month it breaks the index...\n",
    "                #date = dates[min_dateIndex]\n",
    "                #status = c[date]\n",
    "\n",
    "\n",
    "\n",
    "            # Add in the last day\n",
    "            avl_count += 1\n",
    "            days_count += 1\n",
    "\n",
    "            # Get the departure day details??\n",
    "            \n",
    "            if(min_dateIndex >= max_dateIndex): \n",
    "                # Booking runs over the end of the month into the 7th month, which we dont track\n",
    "                # Ignore this booking or just track to the end of the month?\n",
    "                date_dep = None\n",
    "            else:\n",
    "                date_dep = date\n",
    "\n",
    "            # Track the total bookings.\n",
    "            booking_count += booking_days\n",
    "\n",
    "\n",
    "            # Show the booking details\n",
    "            #print(\"{0} -- Arrive: {1} Depart: {2} Total days: {3}\".format(pid,date_arr,date_dep,booking_days))\n",
    "\n",
    "            booking_detail = {\n",
    "                'property_id': pid,\n",
    "                'arr_dt': date_arr,\n",
    "                'dep_dt': date_dep,\n",
    "                'book_days': booking_days\n",
    "            }\n",
    "\n",
    "            if first_page is True:\n",
    "                fp.write('[\\n')\n",
    "                first_page = False\n",
    "            else:\n",
    "                fp.write('\\n,')\n",
    "\n",
    "            json.dump(booking_detail, fp)\n",
    "\n",
    "\n",
    "\n",
    "        #if( status == 'DEP'):\n",
    "        #    dep_count += 1            \n",
    "\n",
    "        if( status == 'UVL'):\n",
    "            uvl_count += 1\n",
    "\n",
    "        min_dateIndex += 1\n",
    "\n",
    "# Close off the JSON\n",
    "fp.write(']')\n",
    "\n",
    "#print(\"Total days: \" + str(days_count))\n",
    "#print(\"Available days: \" + str(avl_count))\n",
    "#print(\"Departure days: \" + str(dep_count))\n",
    "#print(\"Arrival days: \" + str(arr_count))\n",
    "#print(\"Booked days: \" + str(booking_count))\n",
    "#print(\"Unavailable days: \" + str(uvl_count))\n",
    "#print(\"Total check: \" + str(avl_count + booking_count + uvl_count))\n",
    "\n",
    "# Tidy up file handles\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_json('/Users/taj/GitHub/scraping/chrome_stayz_calendar/WebData/stayz_bookings_' + date_str + '.json'\n",
    "                ,convert_dates=['arr_dt','dep_dt'])\n",
    "\n",
    "b.set_index('property_id',inplace=True)\n",
    "\n",
    "#b.head()\n",
    "#bin_values = np.arange(start=0, stop=600, step=10)\n",
    "#b['book_days'].plot(kind='hist', bins=bin_values, figsize=[12,6], alpha=.4) # alpha for transparency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
