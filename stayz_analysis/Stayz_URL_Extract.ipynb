{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def get_base_urls(by_area=False):\n",
    "\n",
    "    # Use the previous days extract to run todays suburbs\n",
    "    #date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    #date_str ='2018-03-22'\n",
    "\n",
    "    # Read the data file and display\n",
    "    nsw_data = pd.read_json('/Users/taj/GitHub/scraping/stayz/WebData/nsw_extract/stayz_nsw_extract_' + date_str + '.json')\n",
    "\n",
    "    nsw_urls = nsw_data['url']\n",
    "\n",
    "    # List to keep all the base urls\n",
    "    base_urls = []\n",
    "\n",
    "    # If we want the breakdown by individual area then call with by_area = True\n",
    "    if by_area:\n",
    "\n",
    "        print(\"Collecting by individual area...\")\n",
    "\n",
    "        for u in nsw_urls:\n",
    "\n",
    "            u_s = u.split('/')\n",
    "\n",
    "            suburb = u_s[-2]\n",
    "            area = u_s[-3]\n",
    "\n",
    "            url = 'https://www.stayz.com.au/accommodation/nsw/' + area + '/' + suburb\n",
    "\n",
    "            if url not in base_urls:\n",
    "                base_urls.append(url)\n",
    "            #else:\n",
    "            #    print(\"Duplicate\")\n",
    "    else:\n",
    "        print(\"Collecing for whole state of NSW\")\n",
    "        base_urls.append('https://www.stayz.com.au/accommodation/nsw')\n",
    "\n",
    "\n",
    "    # Find why the others were not identified?? 4k missing??\n",
    "    return base_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nsw_urls(by_area=False):\n",
    "\n",
    "    # Use the previous days extract to run todays suburbs\n",
    "    #date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    #date_str ='2018-03-22'\n",
    "\n",
    "    # Read the data file and display\n",
    "    nsw_data = pd.read_json('/Users/taj/GitHub/scraping/stayz/WebData/nsw_extract/stayz_nsw_extract_' + date_str + '.json')\n",
    "\n",
    "    nsw_urls = nsw_data['url']\n",
    "\n",
    "    # List to keep all the base urls\n",
    "    base_urls = []\n",
    "\n",
    "    # If we want the breakdown by individual area then call with by_area = True\n",
    "    if by_area:\n",
    "\n",
    "        print(\"Collecting by individual area...\")\n",
    "\n",
    "        for u in nsw_urls:\n",
    "\n",
    "            u_s = u.split('/')\n",
    "\n",
    "            suburb = u_s[-2]\n",
    "            area = u_s[-3]\n",
    "\n",
    "            url = 'https://www.stayz.com.au/accommodation/nsw/' + area + '/' + suburb\n",
    "\n",
    "            #if url not in base_urls:\n",
    "            base_urls.append(url)\n",
    "            #else:\n",
    "            #    print(\"Duplicate\")\n",
    "    else:\n",
    "        print(\"Collecing for whole state of NSW\")\n",
    "        base_urls.append('https://www.stayz.com.au/accommodation/nsw')\n",
    "\n",
    "    # Find why the others were not identified?? 4k missing??\n",
    "    return base_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting by individual area...\n",
      "Collecting by individual area...\n",
      "978\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.stayz.com.au/accommodation/nsw/sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.stayz.com.au/accommodation/nsw/blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.stayz.com.au/accommodation/nsw/hun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.stayz.com.au/accommodation/nsw/exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.stayz.com.au/accommodation/nsw/sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.stayz.com.au/accommodation/nsw/sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.stayz.com.au/accommodation/nsw/sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.stayz.com.au/accommodation/nsw/nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.stayz.com.au/accommodation/nsw/sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.stayz.com.au/accommodation/nsw/sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            url_area\n",
       "0  https://www.stayz.com.au/accommodation/nsw/sou...\n",
       "1  https://www.stayz.com.au/accommodation/nsw/blu...\n",
       "2  https://www.stayz.com.au/accommodation/nsw/hun...\n",
       "3  https://www.stayz.com.au/accommodation/nsw/exp...\n",
       "4  https://www.stayz.com.au/accommodation/nsw/sou...\n",
       "5  https://www.stayz.com.au/accommodation/nsw/sou...\n",
       "6  https://www.stayz.com.au/accommodation/nsw/sou...\n",
       "7  https://www.stayz.com.au/accommodation/nsw/nor...\n",
       "8  https://www.stayz.com.au/accommodation/nsw/sou...\n",
       "9  https://www.stayz.com.au/accommodation/nsw/sou..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the list of base urls\n",
    "base_urls_df = pd.DataFrame(data=get_base_urls(True), columns=['url_area'])\n",
    "nsw_urls_df = pd.DataFrame(data=get_nsw_urls(True), columns=['url_nsw'])\n",
    "\n",
    "\n",
    "\n",
    "comb_data = nsw_urls_df.merge(base_urls_df, how='left',left_on=['url_nsw'], right_on=['url_area'])\n",
    "\n",
    "\n",
    "\n",
    "base_urls_df.fillna('')\n",
    "\n",
    "print(str(len(base_urls_df)))\n",
    "\n",
    "\n",
    "base_urls_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
