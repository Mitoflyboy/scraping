{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sysconfig\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import distutils\n",
    "import scrapy\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import string\n",
    "import re\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.selector import Selector\n",
    "from requests import Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stayz_Calendar(scrapy.Item):\n",
    "    property_id = scrapy.Field()\n",
    "    collection_date = scrapy.Field()\n",
    "    calendar_raw = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup a pipeline\n",
    "class JsonWriterPipeline(object):\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('stayz_calendar.jl','w')\n",
    "        \n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "        \n",
    "    def processitem(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm stayz_calendar.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.thecodeknight.com/post_categories/search/posts/scrapy_python\n",
    "\n",
    "class StayzSpider(scrapy.Spider):\n",
    "    name = 'stayz_crawler'\n",
    "    \n",
    "    # Full scrape - NSW\n",
    "    #start_urls = ['https://www.stayz.com.au/accommodation/nsw']\n",
    "    \n",
    "    # Forbes - has 3 properties on one listing page\n",
    "    start_urls = ['https://www.stayz.com.au/accommodation/nsw/explorer-country/forbes']\n",
    "    \n",
    "    # Orange  - has 122 properties on 3 listing pages\n",
    "    #start_urls = ['https://www.stayz.com.au/accommodation/nsw/explorer-country/orange/']\n",
    "    \n",
    "    #start_urls = ['https://www.stayz.com.au/accommodation/nsw/explorer-country/mudgee'\n",
    "    #             ,'https://www.stayz.com.au/accommodation/nsw/explorer-country/bathurst'\n",
    "    #             ,'https://www.stayz.com.au/accommodation/nsw/north-coast/coffs-harbour'\n",
    "    #             ,'https://www.stayz.com.au/accommodation/nsw/north-coast/port-macquarie']\n",
    "    \n",
    "    #start_urls = ['https://www.stayz.com.au/accommodation/nsw/central-coast/gosford/'\n",
    "    #              ,'https://www.stayz.com.au/accommodation/nsw/explorer-country/orange/'\n",
    "    #             ]\n",
    "    \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, #Used for pipeline 1\n",
    "        'FEED_FORMAT':'json', # Used for pipeline 2\n",
    "        'FEED_URI': 'stayz_calendar.json' #Used for pipeline 2\n",
    "    }\n",
    "    \n",
    "    url_pages = []\n",
    "    \n",
    "    def parse(self, response):\n",
    "        \n",
    "        sel = Selector(response)\n",
    "               \n",
    "        urls = sel.xpath('//section[@class=\"c-search-results__main\"]/div/article/div/div/div/h3/a/@href').extract()\n",
    "                \n",
    "        for u in urls:\n",
    "        \n",
    "            request = scrapy.Request('https://www.stayz.com.au/'+ u, callback=self.parse_results )\n",
    "            \n",
    "            yield request\n",
    "            \n",
    "        # Get the link to the 'Next' page of listings\n",
    "        url_pages = sel.xpath('/html/body/div/main/div/section/div/nav/ul/li/a/@href').extract()\n",
    "        \n",
    "        if len(url_pages) > 0:\n",
    "            nextPage = url_pages[-1]\n",
    "        \n",
    "            nextPageURL = 'https://www.stayz.com.au/'+ nextPage\n",
    "        \n",
    "            print(\"Next URL: \" + str(nextPage))\n",
    "        \n",
    "            yield(scrapy.Request(nextPageURL, callback=self.parse))\n",
    "            \n",
    "    def strip_whitespace(self, st):\n",
    "    \n",
    "        st1 = re.sub('\\n','',st.string() )\n",
    "        st2 = re.sub(' +',' ', st1.string() )\n",
    "        return st2    \n",
    "                \n",
    "    def parse_results(self, response):\n",
    "        \n",
    "        # Property ID - unique for each property\n",
    "        p_id1 = response.selector.xpath('//article/header/ol/li/span/span/text()').extract_first()\n",
    "        p_id2 = re.sub('\\n','',p_id1)\n",
    "        p_id3 = re.sub(' +',' ', p_id2)\n",
    "        p_id4 = re.search('\\d+',p_id3)\n",
    "        p_id = p_id4.group(0)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Ratings and reviews\n",
    "        p_rating = response.selector.xpath('//header[@class=\"c-reviews__header\"]/span/span/span[@class=\"c-facet__label\"]/span/text()').extract_first()\n",
    "        \n",
    "        p_r1 = response.selector.xpath('//html/body/main/section/div/article/header/p[2]/span/span[2]/small/text()').extract_first()\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Scanning Property ID: \" + p_id + \" - \" + \"-\" + response.url)\n",
    "        \n",
    "        p = Stayz_Calendar()\n",
    "        p['property_id'] = p_id\n",
    "        p['calendar_raw'] = 'test'\n",
    "        \n",
    "        yield p        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-31 10:16:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)\n",
      "2018-01-31 10:16:00 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.3.1, w3lib 1.18.0, Twisted 16.6.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct  6 2017, 12:04:38) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 17.2.0 (OpenSSL 1.0.2l  25 May 2017), cryptography 2.0.3, Platform Darwin-17.3.0-x86_64-i386-64bit\n",
      "2018-01-31 10:16:00 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'stayz_calendar.json', 'LOG_LEVEL': 30, 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning Property ID: 153463 - -https://www.stayz.com.au//accommodation/nsw/explorer-country/forbes/153463\n",
      "Scanning Property ID: 207273 - -https://www.stayz.com.au//accommodation/nsw/explorer-country/forbes/207273\n",
      "Scanning Property ID: 147476 - -https://www.stayz.com.au//accommodation/nsw/explorer-country/forbes/147476\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({ 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)' })\n",
    "\n",
    "process.crawl(StayzSpider) \n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
